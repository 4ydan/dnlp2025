{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.glove:Loading GloVe embeddings from glove_embeddings/glove.6B.300d.txt\n",
      "INFO:src.glove:Processed 0 lines\n",
      "INFO:src.glove:Processed 100000 lines\n",
      "INFO:src.glove:Processed 200000 lines\n",
      "INFO:src.glove:Processed 300000 lines\n",
      "INFO:src.glove:Loaded 400004 words with 300d embeddings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from src.config import DCNConfig\n",
    "from src.squad import SquadDataset\n",
    "from src.model import CoattentionModel\n",
    "from src.glove import GloVeEmbeddings\n",
    "\n",
    "\n",
    "config = DCNConfig()\n",
    "\n",
    "glove = GloVeEmbeddings(embedding_dim=config.glove_dim)\n",
    "glove.load_glove_embeddings(config.glove_path)\n",
    "\n",
    "train_dataset = SquadDataset(glove.word_to_idx, split=\"train\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "eval_dataset = SquadDataset(glove.word_to_idx, split=\"validation\")\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "model = CoattentionModel(config.hidden_dim, config.maxout_pool_size, glove.get_embedding_matrix(), config.max_dec_steps, config.dropout_ratio)\n",
    "use_cuda = True if torch.cuda.is_available() else False\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (400004, 300)\n",
      "Vocabulary size: 400004\n",
      "Index of 'the': 4\n",
      "Index of 'McDonald': Not found\n",
      "Index of '<PAD>': 0\n",
      "Index of '<UNK>': 1\n",
      "Total training samples: 87599\n",
      "Total validation samples: 10570\n",
      "\n",
      "\n",
      "Sample #33\n",
      "Context: The P...\n",
      "Question: What team did the Panthers defeat?\n",
      "Answer: (152, 169)\n",
      "Answer: 'Arizona Cardinals'\n",
      "\n",
      "Embedded view:\n",
      "Context IDs: tensor([     4,   9003,   1030,      4,   1389,    199,     21,     11,    408,\n",
      "           221,    180,    388,      5,      9,   3680,  15638,   8115,     19,\n",
      "           568,      4,   2656,    100,   4644,    652,     27,  10047,     28,\n",
      "             6,     43,   1957,      4,   2207,   5508,   3838,    221,    408,\n",
      "            10,      4,  13055,    883,    190,      9,   1981,      8,     48,\n",
      "           130,   1823,   1995,   1886,    112,      4,   4272,     19,   1301,\n",
      "            10,   1014,      6,      4,   7720,   1030,      4,   1389,    199,\n",
      "            21,     11,    425,    221,    413,    388,      5,      9,   1411,\n",
      "             4,     54,    567,   5220,     11,   1023,      8,   3232,     48,\n",
      "           702,     29,   1823,   1995, 334228,     25,   5918,    105,    328,\n",
      "           221,    523,     10,      4,   8943,    883,    190,      6,     43,\n",
      "          1034,      4,   5220,      5,   2695,   5117,      5,      9,   3580,\n",
      "          9845,     23,     52,      7,    137,    780,     16,     37,    120,\n",
      "           506,   3037,     10,      4,   1823,   1995,      6,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0])\n",
      "Context length: tensor([124])\n",
      "Question IDs: tensor([ 106,  149,  123,    4, 9003, 1845,  192,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0])\n",
      "Question length: tensor([7])\n",
      "Answer span: tensor([152, 169])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedding matrix shape: {glove.get_embedding_matrix().shape}\") # Should be (vocab_size, embedding_dim)\n",
    "print(f\"Vocabulary size: {len(glove.word_to_idx)}\")\n",
    "print(f\"Index of 'the': {glove.word_to_idx.get('the', 'Not found')}\")\n",
    "print(f\"Index of 'McDonald': {glove.word_to_idx.get('McDonald', 'Not found')}\")\n",
    "print(f\"Index of '<PAD>': {glove.word_to_idx.get('<PAD>', 'Not found')}\")\n",
    "print(f\"Index of '<UNK>': {glove.word_to_idx.get('<UNK>', 'Not found')}\")\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Total validation samples: {len(eval_dataset)}\")\n",
    "print(\"\")\n",
    "\n",
    "sample_idx = 33\n",
    "print(f\"\\nSample #{sample_idx}\")\n",
    "print(f\"Context: {eval_dataset.context_data[sample_idx][:5]}...\")\n",
    "print(f\"Question: {eval_dataset.question_data[sample_idx]}\")\n",
    "print(f\"Answer: {eval_dataset.answer_span_data[sample_idx]}\")\n",
    "start_pos, end_pos = eval_dataset.answer_span_data[sample_idx]\n",
    "answer_text = eval_dataset.context_data[sample_idx][start_pos:end_pos]\n",
    "print(f\"Answer: '{answer_text}'\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Embedded view:\")\n",
    "context_ids, context_len, question_ids, question_len, answer_span = eval_dataset[sample_idx]\n",
    "\n",
    "print(f\"Context IDs: {context_ids}\")\n",
    "print(f\"Context length: {context_len}\")\n",
    "print(f\"Question IDs: {question_ids}\")\n",
    "print(f\"Question length: {question_len}\")\n",
    "print(f\"Answer span: {answer_span}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 100 loss: 2.771987199783325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 200 loss: 2.885009288787842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 300 loss: 2.846006155014038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 400 loss: 2.773707389831543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 500 loss: 2.906644821166992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 600 loss: 2.8413093090057373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 700 loss: 2.794065237045288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 800 loss: 2.8134536743164062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 900 loss: 2.781519889831543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1000 loss: 3.0760657787323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1100 loss: 2.781520128250122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1200 loss: 2.9062447547912598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Training tracking\n",
    "best_eval_loss = float('inf')\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "print(\"Training started!\")\n",
    "for epoch in trange(config.num_epochs, desc=\"Epoch\"):\n",
    "    epoch_train_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for iteration, batch in enumerate(tqdm(train_dataloader)):\n",
    "        # Unpack the batch\n",
    "        context, context_lens, question, question_lens, answer_spans = batch\n",
    "\n",
    "        if use_cuda:\n",
    "            context = context.cuda()\n",
    "            context_lens = context_lens.view(-1).cuda()\n",
    "            question = question.cuda()\n",
    "            question_lens = question_lens.view(-1).cuda()\n",
    "            answer_spans = answer_spans.cuda()\n",
    "        else:\n",
    "            context_lens = context_lens.view(-1)\n",
    "            question_lens = question_lens.view(-1)\n",
    "        \n",
    "        # Reset gradients\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # === Forward pass ===\n",
    "        loss = model(context, context_lens, question, question_lens, answer_spans)\n",
    "        \n",
    "        # === Backpropagation ===\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss = loss.item()\n",
    "        epoch_train_loss += total_loss\n",
    "        num_batches += 1\n",
    "\n",
    "        if (iteration+1) % config.print_frequency == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} Iteration: {iteration+1} loss: {total_loss}\")\n",
    "            \n",
    "    # Calculate average training loss for this epoch\n",
    "    avg_train_loss = epoch_train_loss / num_batches\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation at the end of each epoch\n",
    "    if (epoch + 1) % config.eval_frequency == 0:  # Note: moved to epoch level\n",
    "        print(\"Running validation...\")\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_batch in eval_dataloader:\n",
    "                context, context_lens, question, question_lens, answer_spans = val_batch\n",
    "                \n",
    "                # Move validation data to device\n",
    "                if use_cuda:\n",
    "                    context = context.cuda()\n",
    "                    context_lens = context_lens.view(-1).cuda()\n",
    "                    question = question.cuda()\n",
    "                    question_lens = question_lens.view(-1).cuda()\n",
    "                    answer_spans = answer_spans.cuda()\n",
    "                else:\n",
    "                    context_lens = context_lens.view(-1)\n",
    "                    question_lens = question_lens.view(-1)\n",
    "                \n",
    "                loss = model(context, context_lens, question, question_lens, answer_spans)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(eval_dataloader)\n",
    "        eval_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch+1} - Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_eval_loss:\n",
    "            best_eval_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_save_path, 'best_model.pt'))\n",
    "            print(\"New best model saved!\")\n",
    "        \n",
    "        model.train()  # Switch back to training mode\n",
    "\n",
    "    # === Save model checkpoint ===\n",
    "    print(\"Saving model checkpoint...\")\n",
    "    os.makedirs(config.model_save_path, exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(config.model_save_path, f'model_epoch_{epoch+1}.pt'))\n",
    "\n",
    "print(\"Training completed!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Plot training curves\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(train_losses, label='Training Loss')\n",
    "# plt.plot(eval_losses, label='Evaluation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Evaluation Loss')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.savefig('training_curves.png')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
