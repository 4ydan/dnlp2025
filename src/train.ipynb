{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.glove:Loading GloVe embeddings from glove_embeddings/glove.840B.300d.txt\n",
      "INFO:src.glove:Processed 0 lines\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from src.config import DCNConfig\n",
    "from src.squad import SquadDataset\n",
    "from src.model import CoattentionModel\n",
    "from src.glove import GloVeEmbeddings\n",
    "\n",
    "\n",
    "config = DCNConfig()\n",
    "\n",
    "glove = GloVeEmbeddings(embedding_dim=config.glove_dim)\n",
    "glove.load_glove_embeddings(config.glove_path)\n",
    "\n",
    "train_dataset = SquadDataset(glove.word_to_idx, split=\"train\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, num_workers=config.num_workers, shuffle=True)\n",
    "\n",
    "eval_dataset = SquadDataset(glove.word_to_idx, split=\"validation\")\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=config.batch_size, num_workers=config.num_workers, shuffle=False)\n",
    "\n",
    "model = CoattentionModel(config.hidden_dim, config.maxout_pool_size, glove.get_embedding_matrix(), config.max_dec_steps, config.dropout_ratio)\n",
    "use_cuda = True if torch.cuda.is_available() else False\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (2196020, 300)\n",
      "Vocabulary size: 2196020\n",
      "Index of 'the': 6\n",
      "Index of 'McDonald': 9172\n",
      "Index of '<PAD>': 0\n",
      "Index of '<UNK>': 1\n",
      "Total training samples: 87599\n",
      "Total validation samples: 10570\n",
      "\n",
      "\n",
      "Sample #33\n",
      "Context: The P...\n",
      "Question: What team did the Panthers defeat?\n",
      "Answer: (152, 169)\n",
      "Answer: 'Arizona Cardinals'\n",
      "\n",
      "Embedded view:\n",
      "Context IDs: tensor([     6,  83217,   1697,      6,   1446,    547,     23,     10,    299,\n",
      "          7956,     70,    922,      4,      7,   9484,   7529,  74034,     34,\n",
      "          1654,      6,  22375,    126,   3505,    986,     18,  96888,     17,\n",
      "             5,     53,   8123,      6,  20240,  50141,   3847,   7956,    299,\n",
      "            11,      6, 147525,   6486,    243,      7,   2141,      8,     62,\n",
      "           345,   2261,   3975,   3071,    270,      6,   6426,     34,   4742,\n",
      "            11,   2858,      5,      6, 109082,   1697,      6,   1446,    547,\n",
      "            23,     10,    254,   7956,    135,    922,      4,      7,   6106,\n",
      "             6,     98,  17932,  41586,     10,   1012,      8,   6149,     62,\n",
      "          1112,     33,   2261,   3975, 492504,     28,  22746,     96,    266,\n",
      "          7956,    383,     11,      6, 157299,   6486,    243,      5,     53,\n",
      "          2485,      6,  41586,      4,  20402,  31732,      4,      7,  42514,\n",
      "         74567,     32,     55,      9,    554,   1700,     19,     35,    175,\n",
      "          2285,   9911,     11,      6,   2261,   3975,      5,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0])\n",
      "Context length: tensor([124])\n",
      "Question IDs: tensor([   82,   336,   131,     6, 83217,  6734,    41,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Question length: tensor([7])\n",
      "Answer span: tensor([152, 169])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedding matrix shape: {glove.get_embedding_matrix().shape}\") # Should be (vocab_size, embedding_dim)\n",
    "print(f\"Vocabulary size: {len(glove.word_to_idx)}\")\n",
    "print(f\"Index of 'the': {glove.word_to_idx.get('the', 'Not found')}\")\n",
    "print(f\"Index of 'McDonald': {glove.word_to_idx.get('McDonald', 'Not found')}\")\n",
    "print(f\"Index of '<PAD>': {glove.word_to_idx.get('<PAD>', 'Not found')}\")\n",
    "print(f\"Index of '<UNK>': {glove.word_to_idx.get('<UNK>', 'Not found')}\")\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Total validation samples: {len(eval_dataset)}\")\n",
    "print(\"\")\n",
    "\n",
    "sample_idx = 33\n",
    "print(f\"\\nSample #{sample_idx}\")\n",
    "print(f\"Context: {eval_dataset.context_data[sample_idx][:5]}...\")\n",
    "print(f\"Question: {eval_dataset.question_data[sample_idx]}\")\n",
    "print(f\"Answer: {eval_dataset.answer_span_data[sample_idx]}\")\n",
    "start_pos, end_pos = eval_dataset.answer_span_data[sample_idx]\n",
    "answer_text = eval_dataset.context_data[sample_idx][start_pos:end_pos]\n",
    "print(f\"Answer: '{answer_text}'\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Embedded view:\")\n",
    "context_ids, context_len, question_ids, question_len, answer_span = eval_dataset[sample_idx]\n",
    "\n",
    "print(f\"Context IDs: {context_ids}\")\n",
    "print(f\"Context length: {context_len}\")\n",
    "print(f\"Question IDs: {question_ids}\")\n",
    "print(f\"Question length: {question_len}\")\n",
    "print(f\"Answer span: {answer_span}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2738 [00:11<?, ?it/s]t/s]\n",
      "Epoch:   0%|          | 0/1 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# === Forward pass ===\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m loss, _, _ \u001b[38;5;241m=\u001b[39m model(context, context_lens, question, question_lens, answer_spans)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# === Backpropagation ===\u001b[39;00m\n\u001b[0;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# Training tracking\n",
    "best_eval_loss = float('inf')\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "print(\"Training started!\")\n",
    "for epoch in trange(config.num_epochs, desc=\"Epoch\"):\n",
    "    epoch_train_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for iteration, batch in enumerate(tqdm(train_dataloader)):\n",
    "        \n",
    "        # Skip batches if enabled\n",
    "        if config.skip_batches:\n",
    "            skip_every = int(1 / (1 - config.skip_ratio))\n",
    "            if iteration % skip_every != 0:\n",
    "                continue\n",
    "        \n",
    "        # Unpack the batch\n",
    "        context, context_lens, question, question_lens, answer_spans = batch\n",
    "\n",
    "        if use_cuda:\n",
    "            context = context.cuda()\n",
    "            context_lens = context_lens.view(-1).cuda()\n",
    "            question = question.cuda()\n",
    "            question_lens = question_lens.view(-1).cuda()\n",
    "            answer_spans = answer_spans.cuda()\n",
    "        else:\n",
    "            context_lens = context_lens.view(-1)\n",
    "            question_lens = question_lens.view(-1)\n",
    "        \n",
    "        # Reset gradients\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # === Forward pass ===\n",
    "        loss, _, _ = model(context, context_lens, question, question_lens, answer_spans)\n",
    "        \n",
    "        # === Backpropagation ===\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss = loss.item()\n",
    "        epoch_train_loss += total_loss\n",
    "        num_batches += 1\n",
    "\n",
    "        if (iteration+1) % config.print_frequency == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} Iteration: {iteration+1} loss: {total_loss}\")\n",
    "            \n",
    "    # Calculate average training loss for this epoch\n",
    "    avg_train_loss = epoch_train_loss / num_batches\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation at the end of each epoch\n",
    "    if (epoch + 1) % config.eval_frequency == 0:  # Note: moved to epoch level\n",
    "        print(\"Running validation...\")\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_batch in eval_dataloader:\n",
    "                context, context_lens, question, question_lens, answer_spans = val_batch\n",
    "                \n",
    "                # Move validation data to device\n",
    "                if use_cuda:\n",
    "                    context = context.cuda()\n",
    "                    context_lens = context_lens.view(-1).cuda()\n",
    "                    question = question.cuda()\n",
    "                    question_lens = question_lens.view(-1).cuda()\n",
    "                    answer_spans = answer_spans.cuda()\n",
    "                else:\n",
    "                    context_lens = context_lens.view(-1)\n",
    "                    question_lens = question_lens.view(-1)\n",
    "                \n",
    "                loss, _, _ = model(context, context_lens, question, question_lens, answer_spans)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(eval_dataloader)\n",
    "        eval_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch+1} - Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_eval_loss:\n",
    "            best_eval_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_save_path, 'best_model.pt'))\n",
    "            print(\"New best model saved!\")\n",
    "        \n",
    "        model.train()  # Switch back to training mode\n",
    "\n",
    "    # === Save model checkpoint ===\n",
    "    print(\"Saving model checkpoint...\")\n",
    "    os.makedirs(config.model_save_path, exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(config.model_save_path, f'model_epoch_{epoch+1}.pt'))\n",
    "\n",
    "print(\"Training completed!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Plot training curves\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(train_losses, label='Training Loss')\n",
    "# plt.plot(eval_losses, label='Evaluation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Evaluation Loss')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.savefig('training_curves.png')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
