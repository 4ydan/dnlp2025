{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.glove:Loading GloVe embeddings from glove_embeddings/glove.840B.300d.txt\n",
      "INFO:src.glove:Processed 0 lines\n",
      "INFO:src.glove:Processed 100000 lines\n",
      "INFO:src.glove:Processed 200000 lines\n",
      "INFO:src.glove:Processed 300000 lines\n",
      "INFO:src.glove:Processed 400000 lines\n",
      "INFO:src.glove:Processed 500000 lines\n",
      "INFO:src.glove:Processed 600000 lines\n",
      "INFO:src.glove:Processed 700000 lines\n",
      "INFO:src.glove:Processed 800000 lines\n",
      "INFO:src.glove:Processed 900000 lines\n",
      "INFO:src.glove:Processed 1000000 lines\n",
      "INFO:src.glove:Processed 1100000 lines\n",
      "INFO:src.glove:Processed 1200000 lines\n",
      "INFO:src.glove:Processed 1300000 lines\n",
      "INFO:src.glove:Processed 1400000 lines\n",
      "INFO:src.glove:Processed 1500000 lines\n",
      "INFO:src.glove:Processed 1600000 lines\n",
      "INFO:src.glove:Processed 1700000 lines\n",
      "INFO:src.glove:Processed 1800000 lines\n",
      "INFO:src.glove:Processed 1900000 lines\n",
      "INFO:src.glove:Processed 2000000 lines\n",
      "INFO:src.glove:Processed 2100000 lines\n",
      "INFO:src.glove:Loaded 2196020 words with 300d embeddings\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from src.config import DCNConfig\n",
    "from src.squad import SquadDataset\n",
    "from src.model import CoattentionModel\n",
    "from src.glove import GloVeEmbeddings\n",
    "\n",
    "\n",
    "config = DCNConfig()\n",
    "\n",
    "glove = GloVeEmbeddings(embedding_dim=config.glove_dim)\n",
    "glove.load_glove_embeddings(config.glove_path)\n",
    "\n",
    "train_dataset = SquadDataset(glove.word_to_idx, split=\"train\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config.batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "eval_dataset = SquadDataset(glove.word_to_idx, split=\"validation\")\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=config.batch_size, num_workers=4, shuffle=False)\n",
    "\n",
    "model = CoattentionModel(config.hidden_dim, config.maxout_pool_size, glove.get_embedding_matrix(), config.max_dec_steps, config.dropout_ratio)\n",
    "use_cuda = True if torch.cuda.is_available() else False\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (2196020, 300)\n",
      "Vocabulary size: 2196020\n",
      "Index of 'the': 6\n",
      "Index of 'McDonald': 9172\n",
      "Index of '<PAD>': 0\n",
      "Index of '<UNK>': 1\n",
      "Total training samples: 87599\n",
      "Total validation samples: 10570\n",
      "\n",
      "\n",
      "Sample #33\n",
      "Context: The P...\n",
      "Question: What team did the Panthers defeat?\n",
      "Answer: (152, 169)\n",
      "Answer: 'Arizona Cardinals'\n",
      "\n",
      "Embedded view:\n",
      "Context IDs: tensor([     6,  83217,   1697,      6,   1446,    547,     23,     10,    299,\n",
      "          7956,     70,    922,      4,      7,   9484,   7529,  74034,     34,\n",
      "          1654,      6,  22375,    126,   3505,    986,     18,  96888,     17,\n",
      "             5,     53,   8123,      6,  20240,  50141,   3847,   7956,    299,\n",
      "            11,      6, 147525,   6486,    243,      7,   2141,      8,     62,\n",
      "           345,   2261,   3975,   3071,    270,      6,   6426,     34,   4742,\n",
      "            11,   2858,      5,      6, 109082,   1697,      6,   1446,    547,\n",
      "            23,     10,    254,   7956,    135,    922,      4,      7,   6106,\n",
      "             6,     98,  17932,  41586,     10,   1012,      8,   6149,     62,\n",
      "          1112,     33,   2261,   3975, 492504,     28,  22746,     96,    266,\n",
      "          7956,    383,     11,      6, 157299,   6486,    243,      5,     53,\n",
      "          2485,      6,  41586,      4,  20402,  31732,      4,      7,  42514,\n",
      "         74567,     32,     55,      9,    554,   1700,     19,     35,    175,\n",
      "          2285,   9911,     11,      6,   2261,   3975,      5,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0])\n",
      "Context length: tensor([124])\n",
      "Question IDs: tensor([   82,   336,   131,     6, 83217,  6734,    41,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Question length: tensor([7])\n",
      "Answer span: tensor([152, 169])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedding matrix shape: {glove.get_embedding_matrix().shape}\") # Should be (vocab_size, embedding_dim)\n",
    "print(f\"Vocabulary size: {len(glove.word_to_idx)}\")\n",
    "print(f\"Index of 'the': {glove.word_to_idx.get('the', 'Not found')}\")\n",
    "print(f\"Index of 'McDonald': {glove.word_to_idx.get('McDonald', 'Not found')}\")\n",
    "print(f\"Index of '<PAD>': {glove.word_to_idx.get('<PAD>', 'Not found')}\")\n",
    "print(f\"Index of '<UNK>': {glove.word_to_idx.get('<UNK>', 'Not found')}\")\n",
    "print(f\"Total training samples: {len(train_dataset)}\")\n",
    "print(f\"Total validation samples: {len(eval_dataset)}\")\n",
    "print(\"\")\n",
    "\n",
    "sample_idx = 33\n",
    "print(f\"\\nSample #{sample_idx}\")\n",
    "print(f\"Context: {eval_dataset.context_data[sample_idx][:5]}...\")\n",
    "print(f\"Question: {eval_dataset.question_data[sample_idx]}\")\n",
    "print(f\"Answer: {eval_dataset.answer_span_data[sample_idx]}\")\n",
    "start_pos, end_pos = eval_dataset.answer_span_data[sample_idx]\n",
    "answer_text = eval_dataset.context_data[sample_idx][start_pos:end_pos]\n",
    "print(f\"Answer: '{answer_text}'\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Embedded view:\")\n",
    "context_ids, context_len, question_ids, question_len, answer_span = eval_dataset[sample_idx]\n",
    "\n",
    "print(f\"Context IDs: {context_ids}\")\n",
    "print(f\"Context length: {context_len}\")\n",
    "print(f\"Question IDs: {question_ids}\")\n",
    "print(f\"Question length: {question_len}\")\n",
    "print(f\"Answer span: {answer_span}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 100 loss: 3.1912336349487305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 200 loss: 2.710130214691162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 300 loss: 2.800063133239746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 400 loss: 2.983147621154785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 500 loss: 2.7745559215545654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 600 loss: 2.826871395111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 700 loss: 2.8351657390594482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 800 loss: 2.8042638301849365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 900 loss: 4.284562110900879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1000 loss: 2.9539341926574707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1100 loss: 2.7651219367980957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1200 loss: 2.8901965618133545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1300 loss: 2.746452808380127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1400 loss: 4.174598693847656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1500 loss: 2.876819610595703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1600 loss: 2.795339584350586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1700 loss: 3.1431493759155273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1800 loss: 2.933516025543213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 1900 loss: 2.9429264068603516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 2000 loss: 2.952594518661499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 2100 loss: 2.634187936782837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 2200 loss: 2.7083544731140137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 2300 loss: 2.8867568969726562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 2400 loss: 2.951230049133301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 2500 loss: 2.9502363204956055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 2600 loss: 2.812074661254883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Iteration: 2700 loss: 2.8950815200805664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2738/2738 [19:23<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [19:33<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m             question_lens \u001b[38;5;241m=\u001b[39m question_lens\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     67\u001b[0m         loss \u001b[38;5;241m=\u001b[39m model(context, context_lens, question, question_lens, answer_spans)\n\u001b[1;32m---> 68\u001b[0m         val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m()\n\u001b[0;32m     70\u001b[0m avg_val_loss \u001b[38;5;241m=\u001b[39m val_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(eval_dataloader)\n\u001b[0;32m     71\u001b[0m eval_losses\u001b[38;5;241m.\u001b[39mappend(avg_val_loss)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "# Training tracking\n",
    "best_eval_loss = float('inf')\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "print(\"Training started!\")\n",
    "for epoch in trange(config.num_epochs, desc=\"Epoch\"):\n",
    "    epoch_train_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    for iteration, batch in enumerate(tqdm(train_dataloader)):\n",
    "        # Unpack the batch\n",
    "        context, context_lens, question, question_lens, answer_spans = batch\n",
    "\n",
    "        if use_cuda:\n",
    "            context = context.cuda()\n",
    "            context_lens = context_lens.view(-1).cuda()\n",
    "            question = question.cuda()\n",
    "            question_lens = question_lens.view(-1).cuda()\n",
    "            answer_spans = answer_spans.cuda()\n",
    "        else:\n",
    "            context_lens = context_lens.view(-1)\n",
    "            question_lens = question_lens.view(-1)\n",
    "        \n",
    "        # Reset gradients\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # === Forward pass ===\n",
    "        loss, _, _ = model(context, context_lens, question, question_lens, answer_spans)\n",
    "        \n",
    "        # === Backpropagation ===\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss = loss.item()\n",
    "        epoch_train_loss += total_loss\n",
    "        num_batches += 1\n",
    "\n",
    "        if (iteration+1) % config.print_frequency == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} Iteration: {iteration+1} loss: {total_loss}\")\n",
    "            \n",
    "    # Calculate average training loss for this epoch\n",
    "    avg_train_loss = epoch_train_loss / num_batches\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation at the end of each epoch\n",
    "    if (epoch + 1) % config.eval_frequency == 0:  # Note: moved to epoch level\n",
    "        print(\"Running validation...\")\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_batch in eval_dataloader:\n",
    "                context, context_lens, question, question_lens, answer_spans = val_batch\n",
    "                \n",
    "                # Move validation data to device\n",
    "                if use_cuda:\n",
    "                    context = context.cuda()\n",
    "                    context_lens = context_lens.view(-1).cuda()\n",
    "                    question = question.cuda()\n",
    "                    question_lens = question_lens.view(-1).cuda()\n",
    "                    answer_spans = answer_spans.cuda()\n",
    "                else:\n",
    "                    context_lens = context_lens.view(-1)\n",
    "                    question_lens = question_lens.view(-1)\n",
    "                \n",
    "                loss, _, _ = model(context, context_lens, question, question_lens, answer_spans)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(eval_dataloader)\n",
    "        eval_losses.append(avg_val_loss)\n",
    "        print(f\"Epoch {epoch+1} - Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_eval_loss:\n",
    "            best_eval_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), os.path.join(config.model_save_path, 'best_model.pt'))\n",
    "            print(\"New best model saved!\")\n",
    "        \n",
    "        model.train()  # Switch back to training mode\n",
    "\n",
    "    # === Save model checkpoint ===\n",
    "    print(\"Saving model checkpoint...\")\n",
    "    os.makedirs(config.model_save_path, exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(config.model_save_path, f'model_epoch_{epoch+1}.pt'))\n",
    "\n",
    "print(\"Training completed!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Plot training curves\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(train_losses, label='Training Loss')\n",
    "# plt.plot(eval_losses, label='Evaluation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Evaluation Loss')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.savefig('training_curves.png')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
